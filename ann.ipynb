{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch import nn, optim\n",
    "import torch.utils.data as data_utils\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean RR</th>\n",
       "      <th>Std RR</th>\n",
       "      <th>HF peak</th>\n",
       "      <th>LF power prc</th>\n",
       "      <th>HF power prc</th>\n",
       "      <th>SD1</th>\n",
       "      <th>SampEn</th>\n",
       "      <th>DFA ɑ1</th>\n",
       "      <th>Etiket\n",
       "PAF=1\n",
       "Non_PAF=0</th>\n",
       "      <th>Kişi numarası</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7109</td>\n",
       "      <td>0.1273</td>\n",
       "      <td>0.4438</td>\n",
       "      <td>0.0753</td>\n",
       "      <td>0.9335</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>0.8583</td>\n",
       "      <td>0.2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7052</td>\n",
       "      <td>0.1032</td>\n",
       "      <td>0.4064</td>\n",
       "      <td>0.0492</td>\n",
       "      <td>0.9257</td>\n",
       "      <td>0.1251</td>\n",
       "      <td>0.6426</td>\n",
       "      <td>0.1596</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7022</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>0.3823</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>0.8228</td>\n",
       "      <td>0.1174</td>\n",
       "      <td>0.7113</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Mean RR  Std RR  HF peak  LF power prc  HF power prc     SD1  SampEn  \\\n",
       "0   0.7109  0.1273   0.4438        0.0753        0.9335  0.1330  0.8583   \n",
       "1   0.7052  0.1032   0.4064        0.0492        0.9257  0.1251  0.6426   \n",
       "2   0.7022  0.1240   0.3823        0.1474        0.8228  0.1174  0.7113   \n",
       "\n",
       "   DFA ɑ1  Etiket\\nPAF=1\\nNon_PAF=0  Kişi numarası  \n",
       "0  0.2020                         1              1  \n",
       "1  0.1596                         1              1  \n",
       "2  0.2397                         1              1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('paf_8.csv')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print data shape and column info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape =  (798, 10) \n",
      "data column names =  Index(['Mean RR', 'Std RR', 'HF peak', 'LF power prc', 'HF power prc', 'SD1',\n",
      "       'SampEn', 'DFA ɑ1', 'Etiket\\nPAF=1\\nNon_PAF=0', 'Kişi numarası'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"data shape = \", data.shape, \"\\ndata column names = \", data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle data by rows to have different input order to system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean RR</th>\n",
       "      <th>Std RR</th>\n",
       "      <th>HF peak</th>\n",
       "      <th>LF power prc</th>\n",
       "      <th>HF power prc</th>\n",
       "      <th>SD1</th>\n",
       "      <th>SampEn</th>\n",
       "      <th>DFA ɑ1</th>\n",
       "      <th>Etiket\n",
       "PAF=1\n",
       "Non_PAF=0</th>\n",
       "      <th>Kişi numarası</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5864</td>\n",
       "      <td>0.2767</td>\n",
       "      <td>0.3347</td>\n",
       "      <td>0.7640</td>\n",
       "      <td>0.6616</td>\n",
       "      <td>0.7151</td>\n",
       "      <td>0.1840</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>0.5380</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.6212</td>\n",
       "      <td>0.3654</td>\n",
       "      <td>0.1113</td>\n",
       "      <td>0.5725</td>\n",
       "      <td>0.4185</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.9485</td>\n",
       "      <td>0.1558</td>\n",
       "      <td>0.2458</td>\n",
       "      <td>0.1701</td>\n",
       "      <td>0.7863</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>0.7930</td>\n",
       "      <td>0.1215</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.5741</td>\n",
       "      <td>0.2085</td>\n",
       "      <td>0.4301</td>\n",
       "      <td>0.3840</td>\n",
       "      <td>0.5485</td>\n",
       "      <td>0.1821</td>\n",
       "      <td>0.3913</td>\n",
       "      <td>0.3656</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>0.8512</td>\n",
       "      <td>0.9117</td>\n",
       "      <td>0.3247</td>\n",
       "      <td>0.3248</td>\n",
       "      <td>0.6880</td>\n",
       "      <td>0.9222</td>\n",
       "      <td>0.5421</td>\n",
       "      <td>0.2900</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Mean RR  Std RR  HF peak  LF power prc  HF power prc     SD1  SampEn  \\\n",
       "666   1.0000  0.5864   0.2767        0.3347        0.7640  0.6616  0.7151   \n",
       "676   0.5380  0.1183   0.0154        0.6212        0.3654  0.1113  0.5725   \n",
       "156   0.9485  0.1558   0.2458        0.1701        0.7863  0.2144  0.7930   \n",
       "56    0.5741  0.2085   0.4301        0.3840        0.5485  0.1821  0.3913   \n",
       "658   0.8512  0.9117   0.3247        0.3248        0.6880  0.9222  0.5421   \n",
       "\n",
       "     DFA ɑ1  Etiket\\nPAF=1\\nNon_PAF=0  Kişi numarası  \n",
       "666  0.1840                         0             82  \n",
       "676  0.4185                         0             83  \n",
       "156  0.1215                         1             27  \n",
       "56   0.3656                         1             10  \n",
       "658  0.2900                         0             81  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = shuffle(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to torch Float Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.FloatTensor(data.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print sample data from new set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data[0,1] =  tensor(0.5864) \n",
      "data.shape = torch.Size([798, 10])\n"
     ]
    }
   ],
   "source": [
    "print(\"data[0,1] = \",data[0,1], \"\\ndata.shape =\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "798"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columnwise normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1094, -0.7559, -1.0000],\n",
      "        [-0.2774, -0.3780,  0.0000],\n",
      "        [-0.8321,  1.1339,  1.0000]])\n"
     ]
    }
   ],
   "source": [
    "def normalize(t):\n",
    "    t = t/t.max(dim=0)[0]\n",
    "    t = (t-t.mean(dim=0))/t.std(dim=0)\n",
    "    return t\n",
    "t = torch.tensor([[1000, 3, 0.15], [500, 4, 0.35], [300, 8, 0.55]])\n",
    "print(normalize(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperating data as input and output 8 column input and 1 column output (ignore 10th column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_in = data[:, 0:8]\n",
    "data_out = data[:, 8:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize only the input columns. Output is binary 0-1 categories. Combine input and output together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_in = normalize(data_in)\n",
    "data_in = data_in.float()\n",
    "data = torch.cat((data_in, data_out), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample data for view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.6651,  2.6944, -0.4889, -0.6968,  1.3485,  3.5215,  1.4209, -1.3894],\n",
       "        [ 0.1514, -0.3708, -1.4923,  0.4537, -0.1272, -0.2385,  0.6304, -0.1848],\n",
       "        [ 2.3849, -0.1253, -0.6075, -1.3577,  1.4311,  0.4659,  1.8528, -1.7104]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data[:, 0:8]\n",
    "x[0:3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data[:, 8:9]\n",
    "y[0:3, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data for train (80%), validation (10%), test (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\ttorch.Size([638, 8]) \n",
      "Validation set: \ttorch.Size([80, 8]) \n",
      "Test set: \t\ttorch.Size([80, 8]) \n",
      "Train label: \t\ttorch.Size([638, 1]) \n",
      "Validation label: \ttorch.Size([80, 1]) \n",
      "Test label: \t\ttorch.Size([80, 1])\n"
     ]
    }
   ],
   "source": [
    "split_frac = 0.8\n",
    "\n",
    "## split data into training, validation, and test data (features and labels, x and y)\n",
    "\n",
    "split_idx = int(len(data)*split_frac)\n",
    "train_x, remaining_x = x[:split_idx], x[split_idx:]\n",
    "train_y, remaining_y = y[:split_idx], y[split_idx:]\n",
    "\n",
    "test_idx = int(len(remaining_x)*0.5)\n",
    "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
    "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
    "\n",
    "## print out the shapes of your resultant feature data\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.size()), \n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape),\n",
    "      \"\\nTrain label: \\t\\t{}\".format(train_y.shape), \n",
    "      \"\\nValidation label: \\t{}\".format(val_y.shape),\n",
    "      \"\\nTest label: \\t\\t{}\".format(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the train validation test dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_utils.TensorDataset(train_x, train_y)\n",
    "train_loader = data_utils.DataLoader(train, batch_size=8, shuffle=True)\n",
    "validation = data_utils.TensorDataset(val_x, val_y)\n",
    "validation_loader = data_utils.DataLoader(validation, batch_size=8, shuffle=True)\n",
    "test = data_utils.TensorDataset(test_x, test_y)\n",
    "test_loader = data_utils.DataLoader(test, batch_size=80, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=8, out_features=32, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.1)\n",
      "  (3): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Dropout(p=0.1)\n",
      "  (6): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (7): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(8, 32),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(0.1),\n",
    "                      nn.Linear(32, 32),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(0.1),\n",
    "                      nn.Linear(32, 1),\n",
    "                      nn.Sigmoid())\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=250, gamma=0.5)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/500..  Training Loss: 0.257..  Validation Loss: 0.279..  Validation Accuracy: 0.000\n",
      "Epoch: 20/500..  Training Loss: 0.204..  Validation Loss: 0.241..  Validation Accuracy: 0.013\n",
      "Epoch: 30/500..  Training Loss: 0.146..  Validation Loss: 0.236..  Validation Accuracy: 0.050\n",
      "Epoch: 40/500..  Training Loss: 0.133..  Validation Loss: 0.308..  Validation Accuracy: 0.075\n",
      "Epoch: 50/500..  Training Loss: 0.121..  Validation Loss: 0.251..  Validation Accuracy: 0.112\n",
      "Epoch: 60/500..  Training Loss: 0.148..  Validation Loss: 0.419..  Validation Accuracy: 0.087\n",
      "Epoch: 70/500..  Training Loss: 0.107..  Validation Loss: 0.488..  Validation Accuracy: 0.112\n",
      "Epoch: 80/500..  Training Loss: 0.101..  Validation Loss: 0.408..  Validation Accuracy: 0.112\n",
      "Epoch: 90/500..  Training Loss: 0.097..  Validation Loss: 0.302..  Validation Accuracy: 0.100\n",
      "Epoch: 100/500..  Training Loss: 0.101..  Validation Loss: 0.318..  Validation Accuracy: 0.100\n",
      "Epoch: 110/500..  Training Loss: 0.100..  Validation Loss: 0.561..  Validation Accuracy: 0.125\n",
      "Epoch: 120/500..  Training Loss: 0.069..  Validation Loss: 0.457..  Validation Accuracy: 0.125\n",
      "Epoch: 130/500..  Training Loss: 0.111..  Validation Loss: 0.521..  Validation Accuracy: 0.125\n",
      "Epoch: 140/500..  Training Loss: 0.063..  Validation Loss: 0.380..  Validation Accuracy: 0.100\n",
      "Epoch: 150/500..  Training Loss: 0.074..  Validation Loss: 0.843..  Validation Accuracy: 0.138\n",
      "Epoch: 160/500..  Training Loss: 0.113..  Validation Loss: 0.475..  Validation Accuracy: 0.112\n",
      "Epoch: 170/500..  Training Loss: 0.063..  Validation Loss: 0.412..  Validation Accuracy: 0.162\n",
      "Epoch: 180/500..  Training Loss: 0.076..  Validation Loss: 0.457..  Validation Accuracy: 0.100\n",
      "Epoch: 190/500..  Training Loss: 0.079..  Validation Loss: 0.471..  Validation Accuracy: 0.138\n",
      "Epoch: 200/500..  Training Loss: 0.058..  Validation Loss: 0.539..  Validation Accuracy: 0.150\n",
      "Epoch: 210/500..  Training Loss: 0.119..  Validation Loss: 0.228..  Validation Accuracy: 0.150\n",
      "Epoch: 220/500..  Training Loss: 0.074..  Validation Loss: 0.372..  Validation Accuracy: 0.162\n",
      "Epoch: 230/500..  Training Loss: 0.132..  Validation Loss: 0.262..  Validation Accuracy: 0.162\n",
      "Epoch: 240/500..  Training Loss: 0.069..  Validation Loss: 0.693..  Validation Accuracy: 0.175\n",
      "Epoch: 250/500..  Training Loss: 0.042..  Validation Loss: 0.571..  Validation Accuracy: 0.150\n",
      "Epoch: 260/500..  Training Loss: 0.035..  Validation Loss: 0.533..  Validation Accuracy: 0.162\n",
      "Epoch: 270/500..  Training Loss: 0.033..  Validation Loss: 0.500..  Validation Accuracy: 0.175\n",
      "Epoch: 280/500..  Training Loss: 0.039..  Validation Loss: 0.575..  Validation Accuracy: 0.150\n",
      "Epoch: 290/500..  Training Loss: 0.040..  Validation Loss: 0.779..  Validation Accuracy: 0.188\n",
      "Epoch: 300/500..  Training Loss: 0.034..  Validation Loss: 0.488..  Validation Accuracy: 0.162\n",
      "Epoch: 310/500..  Training Loss: 0.037..  Validation Loss: 0.576..  Validation Accuracy: 0.175\n",
      "Epoch: 320/500..  Training Loss: 0.039..  Validation Loss: 0.500..  Validation Accuracy: 0.162\n",
      "Epoch: 330/500..  Training Loss: 0.036..  Validation Loss: 0.617..  Validation Accuracy: 0.200\n",
      "Epoch: 340/500..  Training Loss: 0.035..  Validation Loss: 0.476..  Validation Accuracy: 0.200\n",
      "Epoch: 350/500..  Training Loss: 0.019..  Validation Loss: 0.561..  Validation Accuracy: 0.175\n",
      "Epoch: 360/500..  Training Loss: 0.030..  Validation Loss: 0.749..  Validation Accuracy: 0.200\n",
      "Epoch: 370/500..  Training Loss: 0.045..  Validation Loss: 0.580..  Validation Accuracy: 0.200\n",
      "Epoch: 380/500..  Training Loss: 0.020..  Validation Loss: 0.781..  Validation Accuracy: 0.237\n",
      "Epoch: 390/500..  Training Loss: 0.033..  Validation Loss: 0.547..  Validation Accuracy: 0.200\n",
      "Epoch: 400/500..  Training Loss: 0.037..  Validation Loss: 0.468..  Validation Accuracy: 0.213\n",
      "Epoch: 410/500..  Training Loss: 0.030..  Validation Loss: 0.750..  Validation Accuracy: 0.200\n",
      "Epoch: 420/500..  Training Loss: 0.049..  Validation Loss: 0.719..  Validation Accuracy: 0.225\n",
      "Epoch: 430/500..  Training Loss: 0.030..  Validation Loss: 0.620..  Validation Accuracy: 0.200\n",
      "Epoch: 440/500..  Training Loss: 0.029..  Validation Loss: 0.580..  Validation Accuracy: 0.200\n",
      "Epoch: 450/500..  Training Loss: 0.021..  Validation Loss: 0.563..  Validation Accuracy: 0.200\n",
      "Epoch: 460/500..  Training Loss: 0.062..  Validation Loss: 0.563..  Validation Accuracy: 0.213\n",
      "Epoch: 470/500..  Training Loss: 0.023..  Validation Loss: 0.700..  Validation Accuracy: 0.200\n",
      "Epoch: 480/500..  Training Loss: 0.041..  Validation Loss: 0.900..  Validation Accuracy: 0.225\n",
      "Epoch: 490/500..  Training Loss: 0.053..  Validation Loss: 0.855..  Validation Accuracy: 0.237\n",
      "Epoch: 500/500..  Training Loss: 0.042..  Validation Loss: 0.694..  Validation Accuracy: 0.200\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for inputs, labels in train_loader:\n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        log_ps = model(inputs)\n",
    "        \n",
    "        \n",
    "        loss = criterion(log_ps, labels)\n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        val_loss = 0\n",
    "        accuracy = 0\n",
    "        model.eval()\n",
    "        # Turn off gradients for validation, saves memory and computations\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in validation_loader:\n",
    "\n",
    "                log_ps = model(inputs)\n",
    "                \n",
    "                loss = criterion(log_ps, labels)                \n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                equals = log_ps == labels.view(*log_ps.shape)              \n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "        scheduler.step()        \n",
    "        train_losses.append(running_loss/len(train_loader))\n",
    "        val_losses.append(val_loss/len(validation_loader))\n",
    "        if e % 10 == 9:\n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                  \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
    "                  \"Validation Loss: {:.3f}.. \".format(val_loss/len(validation_loader)),\n",
    "                  \"Validation Accuracy: {:.3f}\".format(accuracy/len(validation_loader)))\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.906..  Test Accuracy: 0.262\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "step = 0\n",
    "accuracy = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        log_ps = model(inputs)\n",
    "        \n",
    "                \n",
    "        loss = criterion(log_ps, labels)                \n",
    "        test_loss += loss.item()\n",
    "                \n",
    "        equals = log_ps == labels.view(*log_ps.shape)              \n",
    "        accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "\n",
    "    print(\"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is taken from internet for storing knowledge, not directly related. Don't consider that part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checko.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('checko.pth')\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(8, 50)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dout = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(50, 100)\n",
    "        self.prelu = nn.PReLU(1)\n",
    "        self.out = nn.Linear(100, 1)\n",
    "        self.out_act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        a1 = self.fc1(input_)\n",
    "        h1 = self.relu1(a1)\n",
    "        dout = self.dout(h1)\n",
    "        a2 = self.fc2(dout)\n",
    "        h2 = self.prelu(a2)\n",
    "        a3 = self.out(h2)\n",
    "        y = self.out_act(a3)\n",
    "        return y\n",
    "    \n",
    "net = Net()\n",
    "opt = optim.Adam(net.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(net, opt, criterion, batch_size=50):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for beg_i in range(0, x.size(0), batch_size):\n",
    "        x_batch = x[beg_i:beg_i + batch_size, :]\n",
    "        y_batch = y[beg_i:beg_i + batch_size, :]\n",
    "        x_batch = Variable(x_batch)\n",
    "        y_batch = Variable(y_batch)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        # (1) Forward\n",
    "        y_hat = net(x_batch)\n",
    "        # (2) Compute diff\n",
    "        loss = criterion(y_hat, y_batch)\n",
    "        # (3) Compute gradients\n",
    "        loss.backward()\n",
    "        # (4) update weights\n",
    "        opt.step()        \n",
    "        losses.append(loss.data.numpy())\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_losses = []\n",
    "num_epochs = 100\n",
    "for e in range(num_epochs):\n",
    "    e_losses += train_epoch(net, opt, criterion)\n",
    "plt.plot(e_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
